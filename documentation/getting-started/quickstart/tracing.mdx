---
title: "Quickstart"
description: "Get your first trace in Respan in 5 minutes."
---

<Accordion title="Set up Respan">
1. **Sign up** — Create an account at [platform.respan.ai](https://platform.respan.ai)
2. **Create an API key** — Generate one on the [API keys page](https://platform.respan.ai/platform/api/api-keys)
3. **Add credits or a provider key** — Add credits on the [Credits page](https://platform.respan.ai/platform/api/credits) or connect your own provider key on the [Integrations page](https://platform.respan.ai/platform/api/integrations)
</Accordion>


## 1. Set up your account

Sign up at [platform.respan.ai](https://platform.respan.ai) and create an API key on the [API keys page](https://platform.respan.ai/platform/api/api-keys).

---

## 2. Set up tracing

Pick the method that matches your stack.

<Tabs>

<Tab title="Respan tracing SDK">

Add `@workflow` and `@task` decorators to your code. LLM calls are auto-captured.

<CodeGroup>
```python Python
# pip install respan-tracing
from openai import OpenAI
from respan_tracing.decorators import workflow, task
from respan_tracing.main import RespanTelemetry

k_tl = RespanTelemetry()
client = OpenAI()

@task(name="joke_creation")
def create_joke():
    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": "Tell me a joke about AI"}],
    )
    return completion.choices[0].message.content

@workflow(name="joke_workflow")
def joke_workflow():
    return create_joke()

result = joke_workflow()
print(result)
```
```typescript JavaScript
// npm install @respan/tracing
import { RespanTelemetry } from '@respan/tracing';
import OpenAI from 'openai';

const respanAi = new RespanTelemetry({
    apiKey: process.env.RESPAN_API_KEY || "",
    appName: 'my-app'
});
const openai = new OpenAI();

async function jokeWorkflow() {
    return await respanAi.withWorkflow(
        { name: 'joke_workflow' },
        async () => {
            return await respanAi.withTask(
                { name: 'joke_creation' },
                async () => {
                    const completion = await openai.chat.completions.create({
                        messages: [{ role: 'user', content: 'Tell me a joke about AI' }],
                        model: 'gpt-4o-mini',
                    });
                    return completion.choices[0].message.content;
                }
            );
        }
    );
}

jokeWorkflow().then(console.log);
```
</CodeGroup>

For advanced features (class-based workflows, override span I/O), see [Tracing SDK](/documentation/features/tracing/traces/tracing-sdk).

</Tab>

<Tab title="OpenAI Agents SDK">

Set Respan as the trace processor for the OpenAI Agents SDK.

<CodeGroup>
```python Python
# pip install respan-exporter-openai-agents
import asyncio
from agents import Agent, Runner
from agents.tracing import set_trace_processors, trace
from respan_exporter_openai_agents import RespanTraceProcessor

set_trace_processors([
    RespanTraceProcessor(
        api_key=os.getenv("RESPAN_API_KEY"),
        endpoint=os.getenv("RESPAN_OAIA_TRACING_ENDPOINT"),
    ),
])

async def main():
    agent = Agent(
        name="Assistant",
        instructions="You only respond in haikus.",
    )
    with trace("Hello world test"):
        result = await Runner.run(agent, "Tell me about recursion in programming.")
        print(result.final_output)

asyncio.run(main())
```
```typescript JavaScript
// npm install @respan/exporter-openai-agents
import { Agent, BatchTraceProcessor, run, setTraceProcessors, withTrace } from '@openai/agents';
import { RespanOpenAIAgentsTracingExporter } from '@respan/exporter-openai-agents';

setTraceProcessors([
  new BatchTraceProcessor(
    new RespanOpenAIAgentsTracingExporter(),
  ),
]);

async function main() {
  const agent = new Agent({
    name: 'Assistant',
    instructions: 'You only respond in haikus.',
  });

  const result = await withTrace('Hello World', async () => {
    return run(agent, 'Tell me about recursion in programming.');
  });
  console.log(result.finalOutput);
}

main().catch(console.error);
```
</CodeGroup>

For the full setup guide, see [OpenAI Agents SDK](/integrations/tracing/openai-agents-sdk).

</Tab>

<Tab title="Anthropic Agents SDK">

Set Respan as the exporter for the Anthropic Agents SDK.

<CodeGroup>
```python Python
# pip install respan-exporter-anthropic-agents
import asyncio
from claude_agent_sdk import ClaudeAgentOptions
from respan_exporter_anthropic_agents.respan_anthropic_agents_exporter import (
    RespanAnthropicAgentsExporter,
)

exporter = RespanAnthropicAgentsExporter()

async def main():
    options = exporter.with_options(
        options=ClaudeAgentOptions(
            allowed_tools=["Read", "Glob", "Grep"],
            permission_mode="acceptEdits",
        )
    )
    async for message in exporter.query(
        prompt="Analyze this repository and summarize architecture.",
        options=options,
    ):
        print(message)

asyncio.run(main())
```
```typescript JavaScript
// npm install @respan/exporter-anthropic-agents
import { RespanAnthropicAgentsExporter } from "@respan/exporter-anthropic-agents";

const exporter = new RespanAnthropicAgentsExporter();

async function main() {
  for await (const message of exporter.query({
    prompt: "Review this repository and summarize architecture.",
    options: {
      allowedTools: ["Read", "Glob", "Grep"],
      permissionMode: "acceptEdits",
    },
  })) {
    console.log(message);
  }
}

main().catch(console.error);
```
</CodeGroup>

For the full setup guide, see [Anthropic Agents SDK](/integrations/tracing/anthropic-agents-sdk).

</Tab>

<Tab title="Vercel AI SDK">

Register Respan as the OpenTelemetry exporter and enable telemetry in your AI calls.

```typescript instrumentation.ts
// npm install @respan/exporter-vercel
import { registerOTel } from "@vercel/otel";
import { RespanExporter } from "@respan/exporter-vercel";

export function register() {
  registerOTel({
    serviceName: "next-app",
    traceExporter: new RespanExporter({
      apiKey: process.env.RESPAN_API_KEY,
      baseUrl: process.env.RESPAN_BASE_URL,
      debug: true,
    }),
  });
}
```

```typescript app/api/chat/route.ts
import { openai } from "@ai-sdk/openai";
import { streamText } from "ai";

export async function POST(req: Request) {
  const { messages } = await req.json();

  const result = streamText({
    model: openai("gpt-4o"),
    messages,
    experimental_telemetry: { isEnabled: true },
  });

  return result.toDataStreamResponse();
}
```

For the full setup guide, see [Vercel AI SDK](/integrations/tracing/vercel-tracing).

</Tab>

<Tab title="Others">

<CardGroup cols={3}>

<Card href="/integrations/tracing/opentelemetry">
  OpenTelemetry
</Card>

<Card href="/integrations/tracing/mastra">
  <img className="block dark:hidden" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/Integrations/integration_cards/mastra_v0.png" alt="Mastra" style={{
    pointerEvents: 'none'
  }} />
  <img className="hidden dark:block" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/Integrations/integration_cards/mastra_v0_black.png" alt="Mastra" style={{
    pointerEvents: 'none'
  }} />
</Card>

<Card href="/integrations/tracing/langgraph">
  <img className="block dark:hidden" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/Integrations/integration_cards/langgraph_v0.png" alt="LangGraph" style={{
    pointerEvents: 'none'
  }} />
  <img className="hidden dark:block" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/Integrations/integration_cards/langgraph_v0_black.png" alt="LangGraph" style={{
    pointerEvents: 'none'
  }} />
</Card>

<Card href="/integrations/tracing/haystack">
  <img className="block dark:hidden" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/Integrations/integration_cards/haystack_v0.png" alt="Haystack" style={{
    pointerEvents: 'none'
  }} />
  <img className="hidden dark:block" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/Integrations/integration_cards/haystack_v0_black.png" alt="Haystack" style={{
    pointerEvents: 'none'
  }} />
</Card>

<Card href="/integrations/tracing/baml">
  <img className="block dark:hidden" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/Integrations/integration_cards/baml_v0.png" alt="BAML" style={{
    pointerEvents: 'none'
  }} />
  <img className="hidden dark:block" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/Integrations/integration_cards/baml_v0_black.png" alt="BAML" style={{
    pointerEvents: 'none'
  }} />
</Card>

<Card href="/integrations/tracing/instructor">
  <img className="block dark:hidden" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/Integrations/integration_cards/instructor_v0.png" alt="Instructor" style={{
    pointerEvents: 'none'
  }} />
  <img className="hidden dark:block" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/Integrations/integration_cards/instructor_v0_black.png" alt="Instructor" style={{
    pointerEvents: 'none'
  }} />
</Card>

</CardGroup>

</Tab>

</Tabs>

---

## 3. See your first trace

Open the [Traces page](https://platform.respan.ai/platform/traces) in the Respan dashboard. You should see your trace appear within a few seconds.

<Frame className="rounded-md">
<img width="100%" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/documentation/get-started/overview/trace_tree_v1.png" alt="Agent tracing visualization" />
</Frame>

---

## What's next

- [Enrich your spans](/documentation/features/tracing/traces/span-parameters) with `customer_identifier`, `metadata`, and `thread_identifier`.
- [Set up the gateway](/documentation/features/gateway/setup) to route LLM traffic through one API with fallbacks, retries, and caching.

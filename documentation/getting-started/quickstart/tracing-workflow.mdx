---
title: "Trace & monitor"
description: "Observe your AI system end to end"
icon: "route"
---

<Accordion title="Set up Respan">
1. **Sign up** — Create an account at [platform.respan.ai](https://platform.respan.ai)
2. **Create an API key** — Generate one on the [API keys page](https://platform.respan.ai/platform/api/api-keys)
3. **Add credits or a provider key** — Add credits on the [Credits page](https://platform.respan.ai/platform/api/credits) or connect your own provider key on the [Integrations page](https://platform.respan.ai/platform/api/integrations)
</Accordion>


## Set up tracing

To observe your AI agents, start by setting up tracing. Traces capture the full execution tree of your workflows, every agent step, tool call, and model request in a single view.

We provide different ways to get started. See the [agent tracing quickstart](/documentation/getting-started/quickstart/tracing) for a hands-on walkthrough:

- **[Tracing SDK](/documentation/features/tracing/traces/tracing-sdk)**: install the SDK and add `@workflow` / `@task` decorators to your code. LLM calls are auto-captured. Works with any framework or custom code.
- **[Framework integrations](/documentation/features/tracing/traces/integration-frameworks)**: if you're already using OpenAI Agents SDK, Vercel AI SDK, Mastra, LangGraph, or other frameworks, use our pre-built exporters for zero-effort tracing.
- **[Manual ingestion](/documentation/features/tracing/traces/manual-ingestion)**: send traces directly via the OTLP endpoint or JSON ingest API if you have existing telemetry pipelines.

Once tracing is set up, you can pass [tracing parameters](/documentation/features/tracing/traces/span-parameters) to enrich your spans:

- `customer_identifier`: track per-user metrics, budgets, and rate limits
- `thread_identifier`: group spans into conversation threads
- `trace_group_identifier`: link related traces across sessions
- `metadata`: attach any custom key-value pairs for filtering and tagging

If you don't need full agent tracing and just want to log each LLM call or tool use separately, use the [Logging API](/documentation/getting-started/quickstart/logging) instead. It's a single API call per request, great for simple setups or non-agentic workflows.

---

## Monitor

Once data is flowing into Respan, your [dashboard](/documentation/features/monitoring/metrics) automatically shows requests, tokens, latency, cost, and error rates. You can drill into individual [logs](https://platform.respan.ai/platform/requests) or [traces](https://platform.respan.ai/platform/traces) to debug issues.

To go further, you can set up:

- **[Views](/documentation/features/monitoring/views)**: save reusable filter configurations you apply often (e.g. "production errors", "high-cost requests").
- **[Alerts & notifications](/documentation/features/monitoring/notifications/subscribe_alerts)**: get notified by email when issues are detected, like LLM outages or error spikes.
- **[Automations](/documentation/features/monitoring/automations/quickstart)**: add guardrails to your system by running [online evaluations](/documentation/features/monitoring/automations/quickstart_online_eval) on live traffic, flagging problematic responses, or triggering alerts when quality drops.

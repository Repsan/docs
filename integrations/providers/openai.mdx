---
title: "OpenAI"
description: "Route OpenAI model calls through Respan Gateway and track requests."
---

<Note> This section is for **Respan LLM gateway** users.</Note>

Use Respan Gateway to call OpenAI models while keeping unified observability (logs, cost, latency, and reliability metrics) in Respan.

## Prerequisites
- A **Respan API key**
- An **OpenAI API key** (BYOK)

<CardGroup cols={1}>
  <Card title="Get OpenAI API key" icon="key" href="https://platform.openai.com/account/api-keys">
    Retrieve your API key from the OpenAI platform to begin integration.
  </Card>
</CardGroup>

## Supported SDKs / integrations

<AccordionGroup>
  <Accordion title="✅ Supported Frameworks">
    - [OpenAI SDK](/integrations/gateway/openai/openai-sdk)
    - [LangChain SDK](/integrations/gateway/langchain) 
    - [Vercel/OpenAI](/integrations/gateway/vercel#openai)
    - [Vercel/Google](/integrations/gateway/vercel#google)
    - [LlamaIndex SDK](/integrations/gateway/llama-index)
    - [Google GenAI](/integrations/gateway/google_genai)
    - [Respan native (Otel)](/documentation/getting-started/quickstart/gateway)
  </Accordion>
  
  <Accordion title="❌ Unsupported Frameworks">
    - [Anthropic SDK](/integrations/gateway/anthropic)
    - [Vercel/Anthropic](/integrations/gateway/vercel#anthropic)
  </Accordion>
</AccordionGroup>

## Configuration
There are 2 ways to add your OpenAI credentials to your requests:
### Via UI (Global)

<Steps>
  <Step title="Navigate to Providers">
    Go to the [Providers page](https://platform.respan.ai/platform/api/providers). This page allows you to manage credentials for over 20+ supported providers.
    <Frame>
      <img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/settings/providers.jpg" alt="Respan Providers Page"/>
    </Frame>
  </Step>
  <Step title="Add your OpenAI API Key">
    Select OpenAI and paste your API key.
    <img width="600" src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/Integrations/api_keys/openai_2.png" alt="Add OpenAI Credentials"/>
  </Step>
  <Step title="Configure Load Balancing (Optional)">
    You can add multiple OpenAI API keys for redundancy. Use the `Load balancing weight` field to determine how traffic is distributed between keys.
  </Step>
</Steps>

### Via code (Per-Request)
You can pass credentials dynamically in the request body. This is useful if you need to use your users' own API keys (BYOK).

Add the `customer_credentials` parameter to your [Gateway request](/apis/develop/gateway/chat-completions):

```json
{
  // Rest of the request body
  "customer_credentials": {
    "openai": {
      "api_key": "YOUR_OPENAI_API_KEY",
    }
  }
}
```

## Log OpenAI requests

If you are not using the Gateway to proxy requests, you can still log your OpenAI requests to Respan asynchronously. This allows you to track cost, latency, and performance metrics for external calls.

```python OpenAI Python SDK
import requests

url = "https://api.respan.ai/api/request-logs/create/"
payload = {
    "model": "gpt-4o",
    "prompt_messages": [
        {
            "role": "user",
            "content": "Hello, how are you?"
        }
    ],
    "completion_message": {
        "role": "assistant",
        "content": "I'm doing well, thank you for asking!"
    },
    "cost": 0.0015,
    "generation_time": 2.3,
    "customer_params": {
        "customer_identifier": "user_123"
    }
}
headers = {
    "Authorization": "Bearer YOUR_RESPAN_API_KEY",
    "Content-Type": "application/json"
}

response = requests.post(url, headers=headers, json=payload)
```
<Card title="Get Started with Logging" icon="rocket" href="/documentation/features/tracing/logs/quickstart">
  View the full guide on setting up comprehensive logging for your LLM stack.
</Card>
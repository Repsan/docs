---
title: "Together AI"
description: "Route Together AI model calls through Respan Gateway using your own Together AI credits."
---

<Accordion title="Set up Respan">
1. **Sign up** — Create an account at [platform.respan.ai](https://platform.respan.ai)
2. **Create an API key** — Generate one on the [API keys page](https://platform.respan.ai/platform/api/api-keys)
3. **Add credits or a provider key** — Add credits on the [Credits page](https://platform.respan.ai/platform/api/credits) or connect your own provider key on the [Integrations page](https://platform.respan.ai/platform/api/integrations)
</Accordion>


<Note> This section is for **Respan LLM gateway** users.</Note>

Use Respan Gateway to call **Together AI** models while keeping unified observability (logs, cost, latency, and reliability metrics) in Respan — and optionally charge usage to **your own Together AI credits**.

## Prerequisites
- A **Respan API key**
- A **Together AI API key** (BYOK credits)

<CardGroup cols={1}>
  <Card title="Get Together AI API key" icon="key" href="https://api.together.xyz/settings/api-keys">
    Retrieve your API key from Together AI to begin integration.
  </Card>
</CardGroup>

## Supported SDKs / integrations

<AccordionGroup>
  <Accordion title="✅ Supported Frameworks">
    - [OpenAI SDK](/integrations/gateway/openai/openai-sdk)
    - [LangChain SDK](/integrations/gateway/langchain) 
    - [Vercel/OpenAI](/integrations/gateway/vercel#openai)
    - [Vercel/Google](/integrations/gateway/vercel#google)
    - [LlamaIndex SDK](/integrations/gateway/llama-index)
    - [Google GenAI](/integrations/gateway/google_genai)
    - [Respan native (Otel)](/documentation/getting-started/quickstart/gateway)
  </Accordion>
  
  <Accordion title="❌ Unsupported Frameworks">
    - [Anthropic SDK](/integrations/gateway/anthropic)
    - [Vercel/Anthropic](/integrations/gateway/vercel#anthropic)
  </Accordion>
</AccordionGroup>

## Configuration
There are 2 ways to add your Together AI credentials to your requests:

### Via UI (Global)

<Steps>
  <Step title="Navigate to Providers">
    Go to the [Providers page](https://platform.respan.ai/platform/api/providers). This page allows you to manage credentials for over 20+ supported providers.
    <Frame>
      <img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/settings/providers.jpg" alt="Respan Providers Page"/>
    </Frame>
  </Step>

  <Step title="Add your Together AI API Key">
    Select Together AI and paste your API key.
    {/* Replace with your real screenshot path if different */}
    <Frame>
      <img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/settings/providers.jpg" alt="Add Together AI Credentials"/>
    </Frame>
  </Step>

  <Step title="Configure Load Balancing (Optional)">
    You can add multiple Together AI API keys for redundancy. Use the `Load balancing weight` field to determine how traffic is distributed between keys.
  </Step>
</Steps>

### Via code (Per-Request)
You can pass credentials dynamically in the request body. This is useful if you need to use your users' own API keys (BYOK credits).

Add the `customer_credentials` parameter to your [Gateway request](/apis/develop/gateway/chat-completions):

```json
{
  // Rest of the request body
  "customer_credentials": {
    "togetherai": {
      "api_key": "YOUR_TOGETHERAI_API_KEY"
    }
  }
}
```

## Log Together AI requests

If you are not using the Gateway to proxy requests, you can still log your Together AI requests to Respan asynchronously. This allows you to track cost, latency, and performance metrics for external calls.

```python Together AI Python SDK
import requests

url = "https://api.respan.ai/api/request-logs/create/"
payload = {
    "model": "meta-llama/Llama-3-8b-chat-hf",
    "prompt_messages": [
        {
            "role": "user",
            "content": "Explain machine learning in simple terms"
        }
    ],
    "completion_message": {
        "role": "assistant",
        "content": "Machine learning is like teaching computers to recognize patterns by learning from examples..."
    },
    "cost": 0.0005,
    "generation_time": 2.1,
    "customer_params": {
        "customer_identifier": "user_303"
    }
}
headers = {
    "Authorization": "Bearer YOUR_RESPAN_API_KEY",
    "Content-Type": "application/json"
}

response = requests.post(url, headers=headers, json=payload)
```

<Card title="Get Started with Logging" icon="rocket" href="/documentation/features/tracing/logs/quickstart"> Learn how to set up comprehensive logging for all your LLM requests </Card>

{/* 
## Full request example
<Accordion title="Example">
<CodeGroup>
```python openai_example.py
from openai import OpenAI

client = OpenAI(
    base_url="https://api.respan.ai/api/",
    api_key="YOUR_RESPAN_API_KEY",
)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role":"user", "content":"Tell me a long story"}],
    extra_body={"customer_credentials": {
                  "togetherai": {
                      "api_key": "YOUR_TOGETHER_API_KEY",
                  }
                }
              }
)
```
```python api_example.py
import requests
def demo_call(input, 
              model="gpt-4o",
              token="YOUR_RESPAN_API_KEY"
              ):
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {token}',
    }

    data = {
        'model': model,
        'messages': [{'role': 'user', 'content': input}],
        'customer_credentials': {
            'togetherai': {
                'api_key': "YOUR_TOGETHER_API_KEY",
            }
        }
    }

    response = requests.post('https://api.respan.ai/api/chat/completions', headers=headers, json=data)
    return response

messages = "Say 'Hello World'"
print(demo_call(messages).json())
```
</CodeGroup>
</Accordion> */}
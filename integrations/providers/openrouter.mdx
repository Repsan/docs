---
title: "OpenRouter"
description: "Route OpenRouter model calls through Respan Gateway using your own OpenRouter credits."
---

<Note> This section is for **Respan LLM gateway** users.</Note>

Use Respan Gateway to call **OpenRouter** models while keeping unified observability (logs, cost, latency, and reliability metrics) in Respan — and optionally charge usage to **your own OpenRouter credits**.

## Prerequisites
- A **Respan API key**
- An **OpenRouter API key** (BYOK credits)

<CardGroup cols={1}>
  <Card title="Get OpenRouter API key" icon="key" href="https://openrouter.ai/keys">
    Retrieve your API key from OpenRouter to begin integration.
  </Card>
</CardGroup>

## Supported SDKs / integrations

<AccordionGroup>
  <Accordion title="✅ Supported Frameworks">
    - [OpenAI SDK](/integrations/gateway/openai/openai-sdk)
    - [LangChain SDK](/integrations/gateway/langchain) 
    - [Vercel/OpenAI](/integrations/gateway/vercel#openai)
    - [Vercel/Google](/integrations/gateway/vercel#google)
    - [LlamaIndex SDK](/integrations/gateway/llama-index)
    - [Google GenAI](/integrations/gateway/google_genai)
    - [Respan native (Otel)](/documentation/getting-started/quickstart/gateway)
  </Accordion>
  
  <Accordion title="❌ Unsupported Frameworks">
    - [Anthropic SDK](/integrations/gateway/anthropic)
    - [Vercel/Anthropic](/integrations/gateway/vercel#anthropic)
  </Accordion>
</AccordionGroup>

## Configuration
There are 2 ways to add your OpenRouter credentials to your requests:

### Via UI (Global)

<Steps>
  <Step title="Navigate to Providers">
    Go to the [Providers page](https://platform.respan.ai/platform/api/providers). This page allows you to manage credentials for over 20+ supported providers.
    <Frame>
      <img src="https://keywordsai-static.s3.us-east-1.amazonaws.com/docs/settings/providers.jpg" alt="Respan Providers Page"/>
    </Frame>
  </Step>

  <Step title="Add your OpenRouter API Key">
    Select OpenRouter and paste your API key.
    <Frame>
      <img src="/images/providers/openrouter.png" alt="Add OpenRouter Credentials"/>
    </Frame>
  </Step>

  <Step title="Configure Load Balancing (Optional)">
    You can add multiple OpenRouter API keys for redundancy. Use the `Load balancing weight` field to determine how traffic is distributed between keys.
  </Step>
</Steps>

### Via code (Per-Request)
You can pass credentials dynamically in the request body. This is useful if you need to use your users' own API keys (BYOK credits).

Add the `customer_credentials` parameter to your [Gateway request](/apis/develop/gateway/chat-completions):

```json
{
  // Rest of the request body
  "customer_credentials": {
    "openrouter": {
      "api_key": "YOUR_OPENROUTER_API_KEY"
    }
  }
}
```

## Log OpenRouter requests

If you are not using the Gateway to proxy requests, you can still log your OpenRouter requests to Respan asynchronously. This allows you to track cost, latency, and performance metrics for external calls.

```python OpenRouter Python SDK
import requests

url = "https://api.respan.ai/api/request-logs/create/"
payload = {
    "model": "openai/gpt-4o",
    "prompt_messages": [
        {
            "role": "user",
            "content": "Explain quantum computing"
        }
    ],
    "completion_message": {
        "role": "assistant",
        "content": "Quantum computing is a computing paradigm that uses quantum mechanics to process information..."
    },
    "cost": 0.002,
    "generation_time": 3.1,
    "customer_params": {
        "customer_identifier": "user_789"
    }
}
headers = {
    "Authorization": "Bearer YOUR_RESPAN_API_KEY",
    "Content-Type": "application/json"
}

response = requests.post(url, headers=headers, json=payload)
```

<Card title="Get Started with Logging" icon="rocket" href="/documentation/features/tracing/logs/quickstart"> Learn how to set up comprehensive logging for all your LLM requests </Card>

{/* ## Full request example
<Accordion title="Example">
<CodeGroup>
```python openai_example.py
from openai import OpenAI

client = OpenAI(
    base_url="https://api.respan.ai/api/",
    api_key="YOUR_RESPAN_API_KEY",
)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role":"user", "content":"Tell me a long story"}],
    extra_body={"customer_credentials": {
                  "openrouter": {
                      "api_key": "YOUR_OPENROUTER_API_KEY",
                  }
                }
              }
)
```
```python api_example.py
import requests
def demo_call(input, 
              model="gpt-4o",
              token="YOUR_RESPAN_API_KEY"
              ):
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {token}',
    }

    data = {
        'model': model,
        'messages': [{'role': 'user', 'content': input}],
        'customer_credentials': {
            'openrouter': {
                'api_key': "YOUR_OPENROUTER_API_KEY",
            }
        }
    }

    response = requests.post('https://api.respan.ai/api/chat/completions', headers=headers, json=data)
    return response

messages = "Say 'Hello World'"
print(demo_call(messages).json())
```
</CodeGroup>
</Accordion> */}

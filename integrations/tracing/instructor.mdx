---
title: "Instructor"
description: "Trace your Instructor structured LLM outputs with Respan for monitoring and debugging."
---

<Accordion title="Set up Respan">
1. **Sign up** — Create an account at [platform.respan.ai](https://platform.respan.ai)
2. **Create an API key** — Generate one on the [API keys page](https://platform.respan.ai/platform/api/api-keys)
3. **Add credits or a provider key** — Add credits on the [Credits page](https://platform.respan.ai/platform/api/credits) or connect your own provider key on the [Integrations page](https://platform.respan.ai/platform/api/integrations)
</Accordion>

## What is Instructor?

[Instructor](https://python.useinstructor.com/) is a Python library that makes it easy to get structured data like JSON from LLMs using Pydantic models. Use Instructor with Respan tracing to monitor your structured LLM outputs.

- [Example repo](https://github.com/Repsan/respan-example-projects/tree/main/example_scripts/python/instructor)

## Setup

<Steps>
<Step title="Install packages">

```bash
pip install instructor openai respan-tracing python-dotenv
```

</Step>

<Step title="Set environment variables">

```bash .env
OPENAI_API_KEY=your-openai-api-key
RESPAN_API_KEY=your-respan-api-key
```

</Step>

<Step title="Initialize Respan tracing and run a structured extraction">

```python
import asyncio
import os
from pydantic import BaseModel, Field
import instructor
from openai import AsyncOpenAI
from respan_tracing import RespanTelemetry, Instruments
from respan_tracing.decorators import task
from dotenv import load_dotenv

load_dotenv()

# Initialize Respan tracing
k_tl = RespanTelemetry(
    app_name="instructor-demo",
    instruments={Instruments.OPENAI}
)

# Set up Instructor client
async_client = AsyncOpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
instructor_client = instructor.from_openai(async_client)

# Define your model
class User(BaseModel):
    name: str = Field(description="Full name")
    age: int = Field(description="Age in years")
    email: str = Field(description="Email address")
    role: str = Field(description="Job title")

# Decorate your function
@task(name="extract_user_async")
async def extract_user(text: str) -> User:
    return await instructor_client.chat.completions.create(
        model="gpt-4o-mini",
        response_model=User,
        messages=[
            {"role": "system", "content": "Extract user information from the text."},
            {"role": "user", "content": text}
        ],
        temperature=0.1
    )

async def main():
    user_text = """
    Meet Alex Johnson, a 32-year-old Senior Software Engineer at Google.
    You can reach Alex at alex.johnson@google.com for any technical questions.
    """
    user = await extract_user(user_text)
    print(user.model_dump())

if __name__ == "__main__":
    asyncio.run(main())
```

</Step>

<Step title="View your trace">

Open the [Traces page](https://platform.respan.ai/platform/traces) in the Respan dashboard.

</Step>
</Steps>

## Observability

With this integration, Respan auto-captures:

- **Instructor calls** -- each `@task`-decorated function as a span
- **LLM calls** -- model, input/output messages, token usage (auto-captured via `Instruments.OPENAI`)
- **Structured outputs** -- the Pydantic model returned by Instructor
- **Errors** -- failed extractions and error details

View traces on the [Traces page](https://platform.respan.ai/platform/traces).
